FROM jungfrau70/centos7:ansible.1

USER root
RUN yum install -y java-1.8.0-openjdk-devel
RUN yum install -y which

COPY ./config/install-openssh.sh .
RUN bash install-openssh.sh

COPY ./config/install-hadoop.sh .
RUN bash install-hadoop.sh

COPY ./config/install-hive.sh .
RUN bash install-hive.sh

COPY ./config/install-spark.sh .
RUN bash install-spark.sh

COPY ./config/spark-defaults.conf /usr/local/spark/conf/
COPY ./config/spark-slaves /usr/local/spark/conf/slaves
COPY ./config/spark-env.sh /usr/local/spark/conf/spark-env.sh

COPY ./config/hadoop-workers /opt/hadoop/etc/hadoop/workers
COPY ./config/hadoop-slaves /opt/hadoop/etc/hadoop/slaves
COPY ./config/hadoop-env.sh /opt/hadoop/etc/hadoop/hadoop-env.sh

COPY ./config/core-site.xml /opt/hadoop/etc/hadoop/core-site.xml
COPY ./config/hdfs-site.xml /opt/hadoop/etc/hadoop/hdfs-site.xml
COPY ./config/mapred-site.xml /opt/hadoop/etc/hadoop/mapred-site.xml
COPY ./config/yarn-site.xml /opt/hadoop/etc/hadoop/yarn-site.xml

COPY ./config/hive-env.sh /opt/hive/conf/hive-env.sh
COPY ./config/hive-site.xml /opt/hive/conf/hive-site.xml

RUN rm /opt/hive/lib/guava*.jar && \
    cp /opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar /opt/hive/lib/ || echo "not exist"

### Download a postgresql jar file and copy it to /opt/hive/lib/
RUN wget https://jdbc.postgresql.org/download/postgresql-42.2.24.jar --no-check-certificate -O /opt/hive/lib/postgresql-42.2.24.jar 

## Install  MongoDB JDBC jar in Spark jars folder.
RUN wget https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.11/2.4.0/mongo-spark-connector_2.11-2.4.0.jar --no-check-certificate -O /usr/local/spark/jars/mongo-spark-connector_2.11-2.4.0.jar

RUN yum install -y unzip
COPY ./config/install-livy.sh .
RUN bash install-livy.sh

COPY ./config/livy.conf /usr/local/livy/conf/
RUN mkdir -p /usr/local/livy/logs

COPY ./config/hosts /etc/hosts