Prerequsites:
- Centos7
- Docker engine
- SSH server in deploy-server
- Ansible in deploy-server
- Hadoop cluster with yarn
- Hive with postgres metastore
- Spark cluster with standalone

export WORKDIR='/root/PySpark/Step4_setup_airflow_cluster/2_Airflow'

cd $WORKDIR

https://maxcotec.com/2021/11/apache-airflow-architecture#What-you-will-Learn

https://github.com/maxcotec/Apache-Airflow

https://github.com/Anant/example-airflow-and-spark.git

Reference:
- book: https://www.manning.com/books/data-pipelines-with-apache-airflow
- github : https://github.com/BasPH/data-pipelines-with-apache-airflow