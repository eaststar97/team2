{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2233771ef0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.eventLog.dir', 'hdfs://master:9000/spark-logs'),\n",
       " ('spark.sql.repl.eagerEval.enabled', 'true'),\n",
       " ('spark.jars',\n",
       "  'file:///root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_bson-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar'),\n",
       " ('spark.master', 'spark://master:7077'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,/root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar,/root/.ivy2/jars/org.mongodb_bson-4.0.5.jar,/root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar'),\n",
       " ('spark.history.fs.logDirectory', 'hdfs://master:9000/spark-logs'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_bson-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar'),\n",
       " ('spark.app.initial.file.urls',\n",
       "  'spark://master:32769/files/org.mongodb_mongodb-driver-sync-4.0.5.jar,spark://master:32769/files/org.mongodb_mongodb-driver-core-4.0.5.jar,spark://master:32769/files/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,spark://master:32769/files/org.mongodb_bson-4.0.5.jar'),\n",
       " ('spark.history.provider',\n",
       "  'org.apache.spark.deploy.history.FsHistoryProvider'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.history.fs.update.interval', '10s'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.extraJavaOptions', '-Dderby.system.home=/tmp/derby/'),\n",
       " ('spark.yarn.historyServer.address', 'master:18080'),\n",
       " ('spark.mongodb.output.uri',\n",
       "  'mongodb://root:go2team@mongo/Quake.quakes?authSource=Quake'),\n",
       " ('spark.history.ui.port', '18080'),\n",
       " ('spark.driver.host', 'master'),\n",
       " ('spark.executor.memory', '4g'),\n",
       " ('spark.sql.warehouse.dir', 'hdfs://master:9000/apps/hive/warehouse'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'PySparkShell'),\n",
       " ('spark.files',\n",
       "  'file:///root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_bson-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar'),\n",
       " ('spark.app.initial.jar.urls',\n",
       "  'spark://master:32769/jars/org.mongodb_bson-4.0.5.jar,spark://master:32769/jars/org.mongodb_mongodb-driver-core-4.0.5.jar,spark://master:32769/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar,spark://master:32769/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar'),\n",
       " ('spark.app.startTime', '1647145473079'),\n",
       " ('spark.mongodb.input.uri',\n",
       "  'mongodb://root:go2team@mongo/Quake.quakes?authSource=Quake'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.yarn.jars', 'hdfs:///spark-jars/*.jar'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.id', 'app-20220313042436-0002'),\n",
       " ('spark.executor.cores', '1'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.port', '32769')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/workspace/4_MongoDB\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2528\r\n",
      "drwxr-xr-x. 5 root root     177 Mar 13 04:16  .\r\n",
      "drwxr-xr-x. 9 root root     134 Mar 13 01:08  ..\r\n",
      "drwxr-xr-x. 2 root root      52 Mar 10 14:23  .ipynb_checkpoints\r\n",
      "-rw-r--r--. 1 root root  172074 Mar 13 04:16 'Pyspark Data Pipeline.ipynb'\r\n",
      "drwxr-xr-x. 3 root root      81 Mar 10 09:54  PysparkQuakes\r\n",
      "-rw-r--r--. 1 root root    4003 Mar 13 04:24 'Start Services in Cluster.md'\r\n",
      "drwxr-xr-x. 2 root root    4096 Feb 25 04:21  codes\r\n",
      "-rw-r--r--. 1 root root     530 Mar 13 02:34  commands.txt\r\n",
      "-rw-r--r--. 1 root root 2397103 Mar 10 13:50  database.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls -al /root/workspace/4_MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "\n",
    "EBISYS GitHub\n",
    "\n",
    "https://github.com/EBISYS/WaterWatch\n",
    "\n",
    "    - database.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-03-13 03:51 /apps\r\n",
      "-rw-r--r--   3 root supergroup    2397103 2022-03-13 03:59 /database.csv\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-03-13 03:52 /spark-jars\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-03-13 04:24 /spark-logs\r\n",
      "drwx-wx-wx   - root supergroup          0 2022-03-13 03:46 /tmp\r\n"
     ]
    }
   ],
   "source": [
    "! /opt/hadoop/bin/hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `/database.csv': File exists\r\n"
     ]
    }
   ],
   "source": [
    "! /opt/hadoop/bin/hdfs dfs -put database.csv /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /opt/hadoop/bin/hdfs dfs -put query.csv /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 items\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-03-13 03:51 /apps\r\n",
      "-rw-r--r--   3 root supergroup    2397103 2022-03-13 03:59 /database.csv\r\n",
      "-rw-r--r--   3 root supergroup      72760 2022-03-13 04:34 /query.csv\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-03-13 03:52 /spark-jars\r\n",
      "drwxr-xr-x   - root supergroup          0 2022-03-13 04:24 /spark-logs\r\n",
      "drwx-wx-wx   - root supergroup          0 2022-03-13 03:46 /tmp\r\n"
     ]
    }
   ],
   "source": [
    "! /opt/hadoop/bin/hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession  \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "### Configure spark session\n",
    "#spark = SparkSession\\\n",
    "#    .builder\\\n",
    "#    .master('spark://master:7077')\\\n",
    "#    .appName('quake_etl')\\\n",
    "#    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:2.4.1')\\\n",
    "#    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='01/02/1965', Time='13:44:18', Latitude='19.246', Longitude='145.616', Type='Earthquake', Depth='131.6', Depth Error=None, Depth Seismic Stations=None, Magnitude='6', Magnitude Type='MW', Magnitude Error=None, Magnitude Seismic Stations=None, Azimuthal Gap=None, Horizontal Distance=None, Horizontal Error=None, Root Mean Square=None, ID='ISCGEM860706', Source='ISCGEM', Location Source='ISCGEM', Magnitude Source='ISCGEM', Status='Automatic')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset \n",
    "df_load = spark.read.csv('hdfs://master:9000/database.csv', header=True)\n",
    "# Preview df_load\n",
    "df_load.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Spark UI http://localhost:9090/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+----------+-----+---------+--------------+------------+\n",
      "|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|\n",
      "+----------+--------+---------+----------+-----+---------+--------------+------------+\n",
      "|01/02/1965|  19.246|  145.616|Earthquake|131.6|        6|            MW|ISCGEM860706|\n",
      "|01/04/1965|   1.863|  127.352|Earthquake|   80|      5.8|            MW|ISCGEM860737|\n",
      "|01/05/1965| -20.579| -173.972|Earthquake|   20|      6.2|            MW|ISCGEM860762|\n",
      "|01/08/1965| -59.076|  -23.557|Earthquake|   15|      5.8|            MW|ISCGEM860856|\n",
      "|01/09/1965|  11.938|  126.427|Earthquake|   15|      5.8|            MW|ISCGEM860890|\n",
      "+----------+--------+---------+----------+-----+---------+--------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop fields we don't need from df_load\n",
    "lst_dropped_columns = ['Depth Error', 'Time', 'Depth Seismic Stations','Magnitude Error','Magnitude Seismic Stations','Azimuthal Gap', 'Horizontal Distance','Horizontal Error',\n",
    "    'Root Mean Square','Source','Location Source','Magnitude Source','Status']\n",
    "\n",
    "df_load = df_load.drop(*lst_dropped_columns)\n",
    "# Preview df_load\n",
    "df_load.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
      "|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n",
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
      "|01/02/1965|  19.246|  145.616|Earthquake|131.6|        6|            MW|ISCGEM860706|1965|\n",
      "|01/04/1965|   1.863|  127.352|Earthquake|   80|      5.8|            MW|ISCGEM860737|1965|\n",
      "|01/05/1965| -20.579| -173.972|Earthquake|   20|      6.2|            MW|ISCGEM860762|1965|\n",
      "|01/08/1965| -59.076|  -23.557|Earthquake|   15|      5.8|            MW|ISCGEM860856|1965|\n",
      "|01/09/1965|  11.938|  126.427|Earthquake|   15|      5.8|            MW|ISCGEM860890|1965|\n",
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a year field and add it to the dataframe\n",
    "df_load = df_load.withColumn('Year', year(to_timestamp('Date', 'dd/MM/yyyy')))\n",
    "# Preview df_load\n",
    "df_load.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|Year|Counts|\n",
      "+----+------+\n",
      "|1990|   196|\n",
      "|1975|   150|\n",
      "|1977|   148|\n",
      "|2003|   187|\n",
      "|2007|   211|\n",
      "+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the quakes frequency dataframe using the year field and counts for each year\n",
    "df_quake_freq = df_load.groupBy('Year').count().withColumnRenamed('count', 'Counts')\n",
    "# Preview df_quake_freq\n",
    "df_quake_freq.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Depth: string (nullable = true)\n",
      " |-- Magnitude: string (nullable = true)\n",
      " |-- Magnitude Type: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview df_load schema\n",
    "df_load.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
      "|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n",
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
      "|01/02/1965|  19.246|  145.616|Earthquake|131.6|      6.0|            MW|ISCGEM860706|1965|\n",
      "|01/04/1965|   1.863|  127.352|Earthquake| 80.0|      5.8|            MW|ISCGEM860737|1965|\n",
      "|01/05/1965| -20.579| -173.972|Earthquake| 20.0|      6.2|            MW|ISCGEM860762|1965|\n",
      "|01/08/1965| -59.076|  -23.557|Earthquake| 15.0|      5.8|            MW|ISCGEM860856|1965|\n",
      "|01/09/1965|  11.938|  126.427|Earthquake| 15.0|      5.8|            MW|ISCGEM860890|1965|\n",
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cast some fields from string into numeric types\n",
    "df_load = df_load.withColumn('Latitude', df_load['Latitude'].cast(DoubleType()))\\\n",
    "    .withColumn('Longitude', df_load['Longitude'].cast(DoubleType()))\\\n",
    "    .withColumn('Depth', df_load['Depth'].cast(DoubleType()))\\\n",
    "    .withColumn('Magnitude', df_load['Magnitude'].cast(DoubleType()))\n",
    "\n",
    "# Preview df_load\n",
    "df_load.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Depth: double (nullable = true)\n",
      " |-- Magnitude: double (nullable = true)\n",
      " |-- Magnitude Type: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview df_load schema\n",
    "df_load.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create avg magnitude and max magnitude fields and add to df_quake_freq\n",
    "df_max = df_load.groupBy('Year').max('Magnitude').withColumnRenamed('max(Magnitude)', 'Max_Magnitude')\n",
    "df_avg = df_load.groupBy('Year').avg('Magnitude').withColumnRenamed('avg(Magnitude)', 'Avg_Magnitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----------------+-------------+\n",
      "|Year|Counts|    Avg_Magnitude|Max_Magnitude|\n",
      "+----+------+-----------------+-------------+\n",
      "|1990|   196|5.858163265306125|          7.6|\n",
      "|1975|   150| 5.84866666666667|          7.8|\n",
      "|1977|   148|5.757432432432437|          7.6|\n",
      "|2003|   187|5.850802139037435|          7.6|\n",
      "|2007|   211| 5.89099526066351|          8.4|\n",
      "+----+------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join df_max, and df_avg to df_quake_freq\n",
    "df_quake_freq = df_quake_freq.join(df_avg, ['Year']).join(df_max, ['Year'])\n",
    "# Preview df_quake_freq\n",
    "df_quake_freq.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Year</th><th>Counts</th><th>Avg_Magnitude</th><th>Max_Magnitude</th></tr>\n",
       "<tr><td>1990</td><td>196</td><td>5.858163265306125</td><td>7.6</td></tr>\n",
       "<tr><td>1975</td><td>150</td><td>5.84866666666667</td><td>7.8</td></tr>\n",
       "<tr><td>1977</td><td>148</td><td>5.757432432432437</td><td>7.6</td></tr>\n",
       "<tr><td>2003</td><td>187</td><td>5.850802139037435</td><td>7.6</td></tr>\n",
       "<tr><td>2007</td><td>211</td><td>5.89099526066351</td><td>8.4</td></tr>\n",
       "<tr><td>1974</td><td>147</td><td>5.890476190476194</td><td>7.6</td></tr>\n",
       "<tr><td>2015</td><td>175</td><td>5.842857142857147</td><td>7.5</td></tr>\n",
       "<tr><td>2006</td><td>176</td><td>5.838068181818182</td><td>8.0</td></tr>\n",
       "<tr><td>1978</td><td>158</td><td>5.82215189873418</td><td>7.7</td></tr>\n",
       "<tr><td>2013</td><td>202</td><td>5.861386138613864</td><td>8.0</td></tr>\n",
       "<tr><td>1988</td><td>196</td><td>5.926020408163269</td><td>7.8</td></tr>\n",
       "<tr><td>1997</td><td>183</td><td>5.846448087431697</td><td>7.8</td></tr>\n",
       "<tr><td>1994</td><td>215</td><td>5.867441860465114</td><td>8.3</td></tr>\n",
       "<tr><td>1968</td><td>106</td><td>6.070754716981133</td><td>7.6</td></tr>\n",
       "<tr><td>2014</td><td>198</td><td>5.916666666666668</td><td>8.2</td></tr>\n",
       "<tr><td>1973</td><td>144</td><td>5.833611111111111</td><td>7.4</td></tr>\n",
       "<tr><td>1979</td><td>118</td><td>5.788983050847464</td><td>7.9</td></tr>\n",
       "<tr><td>1971</td><td>148</td><td>5.986486486486491</td><td>7.8</td></tr>\n",
       "<tr><td>1966</td><td>98</td><td>6.060714285714285</td><td>7.7</td></tr>\n",
       "<tr><td>2004</td><td>227</td><td>5.8704845814978</td><td>7.5</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+----+------+-----------------+-------------+\n",
       "|Year|Counts|    Avg_Magnitude|Max_Magnitude|\n",
       "+----+------+-----------------+-------------+\n",
       "|1990|   196|5.858163265306125|          7.6|\n",
       "|1975|   150| 5.84866666666667|          7.8|\n",
       "|1977|   148|5.757432432432437|          7.6|\n",
       "|2003|   187|5.850802139037435|          7.6|\n",
       "|2007|   211| 5.89099526066351|          8.4|\n",
       "|1974|   147|5.890476190476194|          7.6|\n",
       "|2015|   175|5.842857142857147|          7.5|\n",
       "|2006|   176|5.838068181818182|          8.0|\n",
       "|1978|   158| 5.82215189873418|          7.7|\n",
       "|2013|   202|5.861386138613864|          8.0|\n",
       "|1988|   196|5.926020408163269|          7.8|\n",
       "|1997|   183|5.846448087431697|          7.8|\n",
       "|1994|   215|5.867441860465114|          8.3|\n",
       "|1968|   106|6.070754716981133|          7.6|\n",
       "|2014|   198|5.916666666666668|          8.2|\n",
       "|1973|   144|5.833611111111111|          7.4|\n",
       "|1979|   118|5.788983050847464|          7.9|\n",
       "|1971|   148|5.986486486486491|          7.8|\n",
       "|1966|    98|6.060714285714285|          7.7|\n",
       "|2004|   227|  5.8704845814978|          7.5|\n",
       "+----+------+-----------------+-------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove nulls\n",
    "df_load.dropna()\n",
    "df_quake_freq.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
      "|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n",
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
      "|01/02/1965|  19.246|  145.616|Earthquake|131.6|      6.0|            MW|ISCGEM860706|1965|\n",
      "|01/04/1965|   1.863|  127.352|Earthquake| 80.0|      5.8|            MW|ISCGEM860737|1965|\n",
      "|01/05/1965| -20.579| -173.972|Earthquake| 20.0|      6.2|            MW|ISCGEM860762|1965|\n",
      "|01/08/1965| -59.076|  -23.557|Earthquake| 15.0|      5.8|            MW|ISCGEM860856|1965|\n",
      "|01/09/1965|  11.938|  126.427|Earthquake| 15.0|      5.8|            MW|ISCGEM860890|1965|\n",
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview dataframes\n",
    "df_load.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----------------+-------------+\n",
      "|Year|Counts|    Avg_Magnitude|Max_Magnitude|\n",
      "+----+------+-----------------+-------------+\n",
      "|1990|   196|5.858163265306125|          7.6|\n",
      "|1975|   150| 5.84866666666667|          7.8|\n",
      "|1977|   148|5.757432432432437|          7.6|\n",
      "|2003|   187|5.850802139037435|          7.6|\n",
      "|2007|   211| 5.89099526066351|          8.4|\n",
      "+----+------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_quake_freq.show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### (deploy-server) Start MngoDB\n",
    "\n",
    "export WORKDIR='/root/PySpark/Step3_setup_spark_cluster/5_Spark/'\n",
    "cd $WORKDIR\n",
    "cd $WORKDIR && docker-compose -f mongo-docker-compose.yml up -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the tables/collections in mongodb\n",
    "# Write df_load to mongodb\n",
    "df_load.write.format('mongo')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('spark.mongodb.output.uri', 'mongodb://root:go2team@mongo:27017/Quake.quakes?authSource=admin').save()\n",
    "\n",
    "#df_load.write.format('mongo')\\\n",
    "#    .mode('overwrite')\\\n",
    "#    .option('spark.mongodb.output.uri', 'mongodb://mongo/Quake.quakes').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write df_quake_freq to mongodb\n",
    "df_quake_freq.write.format('mongo')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('spark.mongodb.output.uri', 'mongodb://root:go2team@mongo:27017/Quake.quake_freq?authSource=admin').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSection: Machine Learning with Spark\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Section: Machine Learning with Spark\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(time='2017-01-02T00:13:06.300Z', latitude='-36.0365', longitude='51.9288', depth='10', mag='5.7', magType='mwb', nst=None, gap='26', dmin='14.685', rms='1.37', net='us', id='us10007p5d', updated='2017-03-27T23:53:17.040Z', place='Southwest Indian Ridge', type='earthquake', horizontalError='10.3', depthError='1.7', magError='0.068', magNst='21', status='reviewed', locationSource='us', magSource='us')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the test data file into a dataframe\n",
    "#df_test = spark.read.csv(r\"C:\\Users\\Edwin\\Downloads\\query.csv\", header=True)\n",
    "\n",
    "df_test = spark.read.csv('hdfs://master:9000/query.csv', header=True)\n",
    "\n",
    "# Preview df_test\n",
    "df_test.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------+--------+---------+---------+--------------+----------+----+--------------------+\n",
      "|      Date|Depth|          ID|Latitude|Longitude|Magnitude|Magnitude Type|      Type|Year|                 _id|\n",
      "+----------+-----+------------+--------+---------+---------+--------------+----------+----+--------------------+\n",
      "|01/02/1965|131.6|ISCGEM860706|  19.246|  145.616|      6.0|            MW|Earthquake|1965|[622d737dee7ea113...|\n",
      "|01/04/1965| 80.0|ISCGEM860737|   1.863|  127.352|      5.8|            MW|Earthquake|1965|[622d737dee7ea113...|\n",
      "|01/05/1965| 20.0|ISCGEM860762| -20.579| -173.972|      6.2|            MW|Earthquake|1965|[622d737dee7ea113...|\n",
      "|01/08/1965| 15.0|ISCGEM860856| -59.076|  -23.557|      5.8|            MW|Earthquake|1965|[622d737dee7ea113...|\n",
      "|01/09/1965| 15.0|ISCGEM860890|  11.938|  126.427|      5.8|            MW|Earthquake|1965|[622d737dee7ea113...|\n",
      "+----------+-----+------------+--------+---------+---------+--------------+----------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the training data from mongo into a dataframe\n",
    "#df_train = spark.read.format('mongo')\\\n",
    "#    .option('spark.mongodb.input.uri', 'mongodb://127.0.0.1:27017/Quake.quakes').load()\n",
    "\n",
    "df_train = spark.read.format('mongo')\\\n",
    "    .option('spark.mongodb.input.uri', 'mongodb://root:go2team@mongo:27017/Quake.quakes?authSource=admin').load()\n",
    "\n",
    "# Preview df_train\n",
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------+---+------+\n",
      "|                time|latitude|longitude|mag| depth|\n",
      "+--------------------+--------+---------+---+------+\n",
      "|2017-01-02T00:13:...|-36.0365|  51.9288|5.7|    10|\n",
      "|2017-01-02T13:13:...|  -4.895| -76.3675|5.9|   106|\n",
      "|2017-01-02T13:14:...|-23.2513| 179.2383|6.3|551.62|\n",
      "|2017-01-03T09:09:...| 24.0151|  92.0177|5.7|    32|\n",
      "|2017-01-03T21:19:...|-43.3527| -74.5017|5.5| 10.26|\n",
      "+--------------------+--------+---------+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select fields we will use and discard fields we don't need\n",
    "df_test_clean = df_test['time', 'latitude', 'longitude', 'mag', 'depth']\n",
    "# Preview df_test_clean\n",
    "df_test_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------+---------+------+\n",
      "|                Date|Latitude|Longitude|Magnitude| Depth|\n",
      "+--------------------+--------+---------+---------+------+\n",
      "|2017-01-02T00:13:...|-36.0365|  51.9288|      5.7|    10|\n",
      "|2017-01-02T13:13:...|  -4.895| -76.3675|      5.9|   106|\n",
      "|2017-01-02T13:14:...|-23.2513| 179.2383|      6.3|551.62|\n",
      "|2017-01-03T09:09:...| 24.0151|  92.0177|      5.7|    32|\n",
      "|2017-01-03T21:19:...|-43.3527| -74.5017|      5.5| 10.26|\n",
      "+--------------------+--------+---------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename fields\n",
    "df_test_clean = df_test_clean.withColumnRenamed('time', 'Date')\\\n",
    "    .withColumnRenamed('latitude', 'Latitude')\\\n",
    "    .withColumnRenamed('longitude', 'Longitude')\\\n",
    "    .withColumnRenamed('mag', 'Magnitude')\\\n",
    "    .withColumnRenamed('depth', 'Depth')\n",
    "\n",
    "# Preview df_test_clean\n",
    "df_test_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Magnitude: string (nullable = true)\n",
      " |-- Depth: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview Schema\n",
    "df_test_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast some string fields into numeric fields\n",
    "df_test_clean = df_test_clean.withColumn('Latitude', df_test_clean['Latitude'].cast(DoubleType()))\\\n",
    "    .withColumn('Longitude', df_test_clean['Longitude'].cast(DoubleType()))\\\n",
    "    .withColumn('Depth', df_test_clean['Depth'].cast(DoubleType()))\\\n",
    "    .withColumn('Magnitude', df_test_clean['Magnitude'].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Magnitude: double (nullable = true)\n",
      " |-- Depth: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing dataframes\n",
    "df_testing = df_test_clean['Latitude', 'Longitude', 'Magnitude', 'Depth']\n",
    "df_training = df_train['Latitude', 'Longitude', 'Magnitude', 'Depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+-----+\n",
      "|Latitude|Longitude|Magnitude|Depth|\n",
      "+--------+---------+---------+-----+\n",
      "|  19.246|  145.616|      6.0|131.6|\n",
      "|   1.863|  127.352|      5.8| 80.0|\n",
      "| -20.579| -173.972|      6.2| 20.0|\n",
      "| -59.076|  -23.557|      5.8| 15.0|\n",
      "|  11.938|  126.427|      5.8| 15.0|\n",
      "+--------+---------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview df_training\n",
    "df_training.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+------+\n",
      "|Latitude|Longitude|Magnitude| Depth|\n",
      "+--------+---------+---------+------+\n",
      "|-36.0365|  51.9288|      5.7|  10.0|\n",
      "|  -4.895| -76.3675|      5.9| 106.0|\n",
      "|-23.2513| 179.2383|      6.3|551.62|\n",
      "| 24.0151|  92.0177|      5.7|  32.0|\n",
      "|-43.3527| -74.5017|      5.5| 10.26|\n",
      "+--------+---------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview df_testing\n",
    "df_testing.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records with null values from our dataframes\n",
    "df_testing = df_testing.dropna()\n",
    "df_training = df_training.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features to parse into our model and then create the feature vector\n",
    "assembler = VectorAssembler(inputCols=['Latitude', 'Longitude', 'Depth'], outputCol='features')\n",
    "\n",
    "# Create the Model\n",
    "model_reg = RandomForestRegressor(featuresCol='features', labelCol='Magnitude')\n",
    "\n",
    "# Chain the assembler with the model in a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, model_reg])\n",
    "\n",
    "# Train the Model\n",
    "model = pipeline.fit(df_training)\n",
    "\n",
    "# Make the prediction\n",
    "pred_results = model.transform(df_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+------+--------------------+------------------+\n",
      "|Latitude|Longitude|Magnitude| Depth|            features|        prediction|\n",
      "+--------+---------+---------+------+--------------------+------------------+\n",
      "|-36.0365|  51.9288|      5.7|  10.0|[-36.0365,51.9288...| 5.850136724800972|\n",
      "|  -4.895| -76.3675|      5.9| 106.0|[-4.895,-76.3675,...| 5.869637793167875|\n",
      "|-23.2513| 179.2383|      6.3|551.62|[-23.2513,179.238...| 5.896591561887881|\n",
      "| 24.0151|  92.0177|      5.7|  32.0|[24.0151,92.0177,...| 5.931774818629581|\n",
      "|-43.3527| -74.5017|      5.5| 10.26|[-43.3527,-74.501...|5.9204458792780486|\n",
      "+--------+---------+---------+------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview pred_results dataframe\n",
    "pred_results.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.403077\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# rmse should be less than 0.5 for the model to be useful\n",
    "evaluator = RegressionEvaluator(labelCol='Magnitude', predictionCol='prediction', metricName='rmse')\n",
    "rmse = evaluator.evaluate(pred_results)\n",
    "print('Root Mean Squared Error (RMSE) on test data = %g' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------------------+----+-------------------+\n",
      "|Latitude|Longitude|    Pred_Magnitude|Year|               RMSE|\n",
      "+--------+---------+------------------+----+-------------------+\n",
      "|-36.0365|  51.9288| 5.850136724800972|2017|0.40307689171713734|\n",
      "|  -4.895| -76.3675| 5.869637793167875|2017|0.40307689171713734|\n",
      "|-23.2513| 179.2383| 5.896591561887881|2017|0.40307689171713734|\n",
      "| 24.0151|  92.0177| 5.931774818629581|2017|0.40307689171713734|\n",
      "|-43.3527| -74.5017|5.9204458792780486|2017|0.40307689171713734|\n",
      "+--------+---------+------------------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the prediction dataset\n",
    "df_pred_results = pred_results['Latitude', 'Longitude', 'prediction']\n",
    "\n",
    "# Rename the prediction field\n",
    "df_pred_results = df_pred_results.withColumnRenamed('prediction', 'Pred_Magnitude')\n",
    "\n",
    "# Add more columns to our prediction dataset\n",
    "df_pred_results = df_pred_results.withColumn('Year', lit(2017))\\\n",
    "    .withColumn('RMSE', lit(rmse))\n",
    "\n",
    "# Preview df_pred_results\n",
    "df_pred_results.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prediction dataset into mongodb\n",
    "# Write df_pred_results\n",
    "df_pred_results.write.format('mongo')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('spark.mongodb.output.uri', 'mongodb://root:go2team@mongo:27017/Quake.pred_results?authSource=admin').save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "     |################################| 9.5 MB 4.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.1.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python3 -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.0.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (450 kB)\n",
      "     |################################| 450 kB 5.2 MB/s            \n",
      "\u001b[?25hInstalling collected packages: pymongo\n",
      "Successfully installed pymongo-4.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python3 -m pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bokeh\n",
      "  Downloading bokeh-2.3.3.tar.gz (10.7 MB)\n",
      "     |################################| 10.7 MB 4.7 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.8.2)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.6/dist-packages (from bokeh) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from bokeh) (1.19.5)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.6/dist-packages (from bokeh) (8.4.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh) (21.3)\n",
      "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (6.1)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from bokeh) (4.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.9->bokeh) (2.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=16.8->bokeh) (3.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->bokeh) (1.16.0)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.3.3-py3-none-any.whl size=11342785 sha256=9f3a90fa3d992f70b7f9ec68816c25dedfeeb28c05b09c011efac2d1296d5137\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/59/97/257265b741bab184e0cc8f5676309cb1fe6fbda22011bbb3ff\n",
      "Successfully built bokeh\n",
      "Installing collected packages: bokeh\n",
      "Successfully installed bokeh-2.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python3 -m pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import figure, show, ColumnDataSource\n",
    "from bokeh.models.tools import HoverTool\n",
    "import math\n",
    "from math import pi\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.tile_providers import CARTODBPOSITRON\n",
    "from bokeh.themes import built_in_themes\n",
    "from bokeh.io import curdoc\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom read function to read data from mongodb into a dataframe\n",
    "#def read_mongo(host='127.0.0.1', port=27017, username=None, password=None, db='Quake', collection='pred_results'):\n",
    "def read_mongo(host='mongo', port=27017, username='root', password='go2team', db='Quake', collection='pred_results'):\n",
    "    \n",
    "    mongo_uri = 'mongodb://{}:{}@{}:{}/{}.{}?authSource=admin'.format(username, password, host, port, db, collection)\n",
    "    \n",
    "    # Connect to mongodb\n",
    "    conn = MongoClient(mongo_uri)\n",
    "    db = conn[db]\n",
    "    \n",
    "    # Select all records from the collection\n",
    "    cursor = db[collection].find()\n",
    "    \n",
    "    # Create the dataframe\n",
    "    df = pd.DataFrame(list(cursor))\n",
    "    \n",
    "    # Delete the _id field\n",
    "    del df['_id']\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets from mongodb\n",
    "df_quakes = read_mongo(collection='quakes')\n",
    "df_quake_freq = read_mongo(collection='quake_freq')\n",
    "df_quake_pred = read_mongo(collection='pred_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Type</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Magnitude Type</th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22943</th>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>-50.5575</td>\n",
       "      <td>139.4489</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.3</td>\n",
       "      <td>MWW</td>\n",
       "      <td>US10004ANT</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22944</th>\n",
       "      <td>01/01/2016</td>\n",
       "      <td>-28.6278</td>\n",
       "      <td>-177.2810</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>34.00</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MWW</td>\n",
       "      <td>US10004AQY</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22945</th>\n",
       "      <td>01/02/2016</td>\n",
       "      <td>44.8069</td>\n",
       "      <td>129.9406</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>585.47</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MWW</td>\n",
       "      <td>US10004ATB</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22946</th>\n",
       "      <td>01/03/2016</td>\n",
       "      <td>24.8036</td>\n",
       "      <td>93.6505</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>55.00</td>\n",
       "      <td>6.7</td>\n",
       "      <td>MWW</td>\n",
       "      <td>US10004B2N</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22947</th>\n",
       "      <td>01/05/2016</td>\n",
       "      <td>30.6132</td>\n",
       "      <td>132.7337</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MWW</td>\n",
       "      <td>US10004BEN</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Latitude  Longitude        Type   Depth  Magnitude  \\\n",
       "22943  01/01/2016  -50.5575   139.4489  Earthquake   10.00        6.3   \n",
       "22944  01/01/2016  -28.6278  -177.2810  Earthquake   34.00        5.8   \n",
       "22945  01/02/2016   44.8069   129.9406  Earthquake  585.47        5.8   \n",
       "22946  01/03/2016   24.8036    93.6505  Earthquake   55.00        6.7   \n",
       "22947  01/05/2016   30.6132   132.7337  Earthquake    4.71        5.8   \n",
       "\n",
       "      Magnitude Type          ID    Year  \n",
       "22943            MWW  US10004ANT  2016.0  \n",
       "22944            MWW  US10004AQY  2016.0  \n",
       "22945            MWW  US10004ATB  2016.0  \n",
       "22946            MWW  US10004B2N  2016.0  \n",
       "22947            MWW  US10004BEN  2016.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quakes_2016 = df_quakes[df_quakes['Year'] == 2016]\n",
    "# Preview df_quakes_2016\n",
    "df_quakes_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show plots embedded in jupyter notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom style function to style our plots\n",
    "def style(p):\n",
    "    # Title\n",
    "    p.title.align='center'\n",
    "    p.title.text_font_size='20pt'\n",
    "    p.title.text_font='serif'\n",
    "    \n",
    "    # Axis titles\n",
    "    p.xaxis.axis_label_text_font_size='14pt'\n",
    "    p.xaxis.axis_label_text_font_style='bold'\n",
    "    p.yaxis.axis_label_text_font_size='14pt'\n",
    "    p.yaxis.axis_label_text_font_style='bold'\n",
    "    \n",
    "    # Tick labels\n",
    "    p.xaxis.major_label_text_font_size='12pt'\n",
    "    p.yaxis.major_label_text_font_size='12pt'\n",
    "    \n",
    "    # Plot the legend in the top left corner\n",
    "    p.legend.location='top_left'\n",
    "    \n",
    "    return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Geo Map plot\n",
    "def plotMap():\n",
    "    lat = df_quakes_2016['Latitude'].values.tolist()\n",
    "    lon = df_quakes_2016['Longitude'].values.tolist()\n",
    "    \n",
    "    pred_lat = df_quake_pred['Latitude'].values.tolist()\n",
    "    pred_lon = df_quake_pred['Longitude'].values.tolist()\n",
    "    \n",
    "    lst_lat = []\n",
    "    lst_lon = []\n",
    "    lst_pred_lat = []\n",
    "    lst_pred_lon = []\n",
    "    \n",
    "    i=0\n",
    "    j=0\n",
    "    \n",
    "    # Convert Lat and Long values into merc_projection format\n",
    "    for i in range(len(lon)):\n",
    "        r_major = 6378137.000\n",
    "        x = r_major * math.radians(lon[i])\n",
    "        scale = x/lon[i]\n",
    "        y = 180.0/math.pi * math.log(math.tan(math.pi/4.0 +\n",
    "            lat[i] * (math.pi/180.0)/2.0)) * scale\n",
    "        \n",
    "        lst_lon.append(x)\n",
    "        lst_lat.append(y)\n",
    "        i += 1\n",
    "        \n",
    "    # Convert predicted lat and long values into merc_projection format\n",
    "    for j in range(len(pred_lon)):\n",
    "        r_major = 6378137.000\n",
    "        x = r_major * math.radians(pred_lon[j])\n",
    "        scale = x/pred_lon[j]\n",
    "        y = 180.0/math.pi * math.log(math.tan(math.pi/4.0 +\n",
    "            pred_lat[j] * (math.pi/180.0)/2.0)) * scale\n",
    "        \n",
    "        lst_pred_lon.append(x)\n",
    "        lst_pred_lat.append(y)\n",
    "        j += 1\n",
    "    \n",
    "    \n",
    "    df_quakes_2016['coords_x'] = lst_lat\n",
    "    df_quakes_2016['coords_y'] = lst_lon\n",
    "    df_quake_pred['coords_x'] = lst_pred_lat\n",
    "    df_quake_pred['coords_y'] = lst_pred_lon\n",
    "    \n",
    "    # Scale the circles\n",
    "    df_quakes_2016['Mag_Size'] = df_quakes_2016['Magnitude'] * 4\n",
    "    df_quake_pred['Mag_Size'] = df_quake_pred['Pred_Magnitude'] * 4\n",
    "    \n",
    "    # create datasources for our ColumnDataSource object\n",
    "    lats = df_quakes_2016['coords_x'].tolist()\n",
    "    longs = df_quakes_2016['coords_y'].tolist()\n",
    "    mags = df_quakes_2016['Magnitude'].tolist()\n",
    "    years = df_quakes_2016['Year'].tolist()\n",
    "    mag_size = df_quakes_2016['Mag_Size'].tolist()\n",
    "    \n",
    "    pred_lats = df_quake_pred['coords_x'].tolist()\n",
    "    pred_longs = df_quake_pred['coords_y'].tolist()\n",
    "    pred_mags = df_quake_pred['Pred_Magnitude'].tolist()\n",
    "    pred_year = df_quake_pred['Year'].tolist()\n",
    "    pred_mag_size = df_quake_pred['Mag_Size'].tolist()\n",
    "    \n",
    "    # Create column datasource\n",
    "    cds = ColumnDataSource(\n",
    "        data=dict(\n",
    "            lat=lats,\n",
    "            lon=longs,\n",
    "            mag=mags,\n",
    "            year=years,\n",
    "            mag_s=mag_size\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    pred_cds = ColumnDataSource(\n",
    "        data=dict(\n",
    "            pred_lat=pred_lats,\n",
    "            pred_long=pred_longs,\n",
    "            pred_mag=pred_mags,\n",
    "            year=pred_year,\n",
    "            pred_mag_s=pred_mag_size\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Tooltips\n",
    "    TOOLTIPS = [\n",
    "        (\"Year\", \" @year\"),\n",
    "        (\"Magnitude\", \" @mag\"),\n",
    "        (\"Predicted Magnitude\", \" @pred_mag\")\n",
    "    ]\n",
    "    \n",
    "    # Create figure\n",
    "    p = figure(title='Earthquake Map',\n",
    "              plot_width=2300, plot_height=450,\n",
    "              x_range=(-2000000, 6000000),\n",
    "              y_range=(-1000000, 7000000),\n",
    "              tooltips=TOOLTIPS)\n",
    "    \n",
    "    p.circle(x='lon', y='lat', size='mag_s', fill_color='#cc0000', fill_alpha=0.7,\n",
    "            source=cds, legend='Quakes 2016')\n",
    "    \n",
    "    # Add circles for our predicted earthquakes\n",
    "    p.circle(x='pred_long', y='pred_lat', size='pred_mag_s', fill_color='#ccff33', fill_alpha=7.0,\n",
    "            source=pred_cds, legend='Predicted Quakes 2017')\n",
    "    \n",
    "    p.add_tile(CARTODBPOSITRON)\n",
    "    \n",
    "    # Style the map plot\n",
    "    # Title\n",
    "    p.title.align='center'\n",
    "    p.title.text_font_size='20pt'\n",
    "    p.title.text_font='serif'\n",
    "    \n",
    "    # Legend\n",
    "    p.legend.location='bottom_right'\n",
    "    p.legend.background_fill_color='black'\n",
    "    p.legend.background_fill_alpha=0.8\n",
    "    p.legend.click_policy='hide'\n",
    "    p.legend.label_text_color='white'\n",
    "    p.xaxis.visible=False\n",
    "    p.yaxis.visible=False\n",
    "    p.axis.axis_label=None\n",
    "    p.axis.visible=False\n",
    "    p.grid.grid_line_color=None\n",
    "    \n",
    "    \n",
    "    show(p)\n",
    "    \n",
    "    return p\n",
    "    \n",
    "plotMap()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bar Chart\n",
    "def plotBar():\n",
    "    # Load the datasource \n",
    "    cds = ColumnDataSource(data=dict(\n",
    "        yrs = df_quake_freq['Year'].values.tolist(),\n",
    "        numQuakes = df_quake_freq['Counts'].values.tolist()\n",
    "    ))\n",
    "    \n",
    "    # Tooltip\n",
    "    TOOLTIPS = [\n",
    "        ('Year', ' @yrs'),\n",
    "        ('Number of earthquakes', ' @numQuakes')\n",
    "    ]\n",
    "    \n",
    "    # Create a figure\n",
    "    barChart = figure(title='Frequency of Earthquakes by Year',\n",
    "                     plot_height=400,\n",
    "                     plot_width=1150,\n",
    "                     x_axis_label='Years',\n",
    "                     y_axis_label='Number of Occurances',\n",
    "                     x_minor_ticks=2,\n",
    "                     y_range=(0, df_quake_freq['Counts'].max() + 100),\n",
    "                     toolbar_location=None,\n",
    "                     tooltips=TOOLTIPS)\n",
    "    \n",
    "    # Create a vertical bar \n",
    "    barChart.vbar(x='yrs', bottom=0, top='numQuakes',\n",
    "                 color='#cc0000', width=0.75,\n",
    "                 legend='Year', source=cds)\n",
    "    \n",
    "    # Style the bar chart\n",
    "    barChart = style(barChart)\n",
    "    \n",
    "    #show(barChart)\n",
    "    \n",
    "    return barChart\n",
    "    \n",
    "    \n",
    "#plotBar()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Avg_Magnitude</th>\n",
       "      <th>Max_Magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>196</td>\n",
       "      <td>5.858163</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>150</td>\n",
       "      <td>5.848667</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1977</td>\n",
       "      <td>148</td>\n",
       "      <td>5.757432</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>187</td>\n",
       "      <td>5.850802</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>211</td>\n",
       "      <td>5.890995</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Counts  Avg_Magnitude  Max_Magnitude\n",
       "0  1990     196       5.858163            7.6\n",
       "1  1975     150       5.848667            7.8\n",
       "2  1977     148       5.757432            7.6\n",
       "3  2003     187       5.850802            7.6\n",
       "4  2007     211       5.890995            8.4"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quake_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a magnitude plot\n",
    "def plotMagnitude():\n",
    "    # Load the datasource\n",
    "    cds = ColumnDataSource(data=dict(\n",
    "        yrs = df_quake_freq['Year'].values.tolist(),\n",
    "        avg_mag = df_quake_freq['Avg_Magnitude'].round(1).values.tolist(),\n",
    "        max_mag = df_quake_freq['Max_Magnitude'].values.tolist()\n",
    "    ))\n",
    "    \n",
    "    # Tooltip\n",
    "    TOOLTIPS = [\n",
    "        ('Year', ' @yrs'),\n",
    "        ('Average Magnitude', ' @avg_mag'),\n",
    "        ('Maximum Magnitude', ' @max_mag')\n",
    "    ]\n",
    "    \n",
    "    # Create the figure\n",
    "    mp = figure(title='Maximum and Average Magnitude by Year',\n",
    "               plot_width=1150, plot_height=400,\n",
    "               x_axis_label='Years',\n",
    "               y_axis_label='Magnitude',\n",
    "               x_minor_ticks=2,\n",
    "               y_range=(5, df_quake_freq['Max_Magnitude'].max() + 1),\n",
    "               toolbar_location=None,\n",
    "               tooltips=TOOLTIPS)\n",
    "    \n",
    "    # Max Magnitude\n",
    "    mp.line(x='yrs', y='max_mag', color='#cc0000', line_width=2, legend='Max Magnitude', source=cds)\n",
    "    mp.circle(x='yrs', y='max_mag', color='#cc0000', size=8, fill_color='#cc0000', source=cds)\n",
    "    \n",
    "    # Average Magnitude \n",
    "    mp.line(x='yrs', y='avg_mag', color='yellow', line_width=2, legend='Avg Magnitude', source=cds)\n",
    "    mp.circle(x='yrs', y='avg_mag', color='yellow', size=8, fill_color='yellow', source=cds)\n",
    "    \n",
    "    mp = style(mp)\n",
    "    \n",
    "    #show(mp)\n",
    "    \n",
    "    return mp\n",
    "\n",
    "#plotMagnitude()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the visuals directly in the browser\n",
    "output_file('dashboard.html')\n",
    "# Change to a dark theme\n",
    "curdoc().theme = 'dark_minimal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "failed to validate TileRenderer(id='1075', ...).tile_source: expected an instance of type TileSource, got CARTODBPOSITRON of type str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-41b9540a8f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Make the grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplotMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mplotBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotMagnitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Shor the grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-73e810ab2dbe>\u001b[0m in \u001b[0;36mplotMap\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m             source=pred_cds, legend='Predicted Quakes 2017')\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCARTODBPOSITRON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Style the map plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bokeh/models/plots.py\u001b[0m in \u001b[0;36madd_tile\u001b[0;34m(self, tile_source, **kw)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         '''\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mtile_renderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTileRenderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtile_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtile_renderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bokeh/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mdefault_theme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bokeh/core/has_props.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **properties)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bokeh/core/has_props.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdescriptor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdifflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_close_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"similar\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bokeh/core/property/descriptors.py\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, obj, value, setter)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{class_name}.{self.name} is a readonly property\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delete__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bokeh/core/property/descriptors.py\u001b[0m in \u001b[0;36m_internal_set\u001b[0;34m(self, obj, value, hint, setter)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \"\"\"\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_real_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bokeh/core/property/bases.py\u001b[0m in \u001b[0;36mprepare_value\u001b[0;34m(self, owner, name, value)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mobj_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHasProps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"failed to validate {obj_repr}.{name}: {error}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHasProps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: failed to validate TileRenderer(id='1075', ...).tile_source: expected an instance of type TileSource, got CARTODBPOSITRON of type str"
     ]
    }
   ],
   "source": [
    "# Build the grid plot\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "# Make the grid\n",
    "grid = gridplot([[plotMap()], [plotBar(), plotMagnitude()]])\n",
    "\n",
    "# Shor the grid\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
